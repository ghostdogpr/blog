<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Astro v5.13.7"><!-- Favicons --><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="apple-mobile-web-app-title" content="Pierre Ricadat's Tech Blog"><!-- Canonical URL --><link rel="canonical" href="https://blog.pierre-ricadat.com/supporting-high-performance-response-streaming-in-shardcake/"><!-- Primary Meta Tags --><title>Supporting high-performance response streaming in Shardcake</title><meta name="title" content="Supporting high-performance response streaming in Shardcake"><meta name="description" content="Shardcake is a Scala open source library I created in 2022 to easily distribute entities across multiple servers (sharding) and to interact with them using t...
"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://blog.pierre-ricadat.com/supporting-high-performance-response-streaming-in-shardcake/"><meta property="og:title" content="Supporting high-performance response streaming in Shardcake"><meta property="og:description" content="Shardcake is a Scala open source library I created in 2022 to easily distribute entities across multiple servers (sharding) and to interact with them using t...
"><meta property="og:image" content="https://blog.pierre-ricadat.com/saral-og.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://blog.pierre-ricadat.com/supporting-high-performance-response-streaming-in-shardcake/"><meta property="twitter:title" content="Supporting high-performance response streaming in Shardcake"><meta property="twitter:description" content="Shardcake is a Scala open source library I created in 2022 to easily distribute entities across multiple servers (sharding) and to interact with them using t...
"><meta property="twitter:image" content="https://blog.pierre-ricadat.com/saral-og.jpg"><!-- RSS Auto-discovery --><link rel="alternate" type="application/rss+xml" title="Pierre Ricadat's Tech Blog RSS Feed" href="https://blog.pierre-ricadat.com/rss.xml"><link rel="stylesheet" href="/_astro/_slug_.DSRIcTml.css"><script>!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=Object.assign(w[p]||{},{"lib":"/~partytown/","debug":false});c[f]=(c[f]||[]).concat(["dataLayer.push"])})(window,'partytown','forward');/* Partytown 0.11.2 - MIT QwikDev */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,l,d,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(d=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(l=setTimeout(v,(null==s?void 0:s.fallbackTimeout)||1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.11.2":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<d.length;n++)(o=r.createElement("script")).innerHTML=d[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(l)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);;(e=>{e.addEventListener("astro:before-swap",e=>{let r=document.body.querySelector("iframe[src*='/~partytown/']");if(r)e.newDocument.body.append(r)})})(document);</script></head> <body class="text-foreground bg-background font-light dark:text-foreground-dark dark:bg-background-dark transition-colors"> <header class="fixed top-0 w-full z-40 bg-background dark:bg-background-dark"> <nav class=""> <div class="app-container flex justify-between items-center py-5"> <a href="/" aria-label="Home"> <svg width="36" height="36" viewBox="0 0 36 36" fill="none">
  <rect width="36" height="36" rx="8" fill="currentColor" opacity="0.1" />
  <text x="18" y="25" font-family="system-ui, -apple-system, sans-serif" font-size="18" font-weight="700" fill="currentColor" text-anchor="middle">PR</text>
</svg> </a> <div class="gap-8 hidden md:flex items-center"> <a href="/" class="text-lg" target="_self" data-astro-cid-rieiwi5x> Blog </a> <a href="https://github.com/sponsors/ghostdogpr" class="text-lg" target="_blank" data-astro-cid-rieiwi5x> Sponsor </a>  <div class="border-[1px] border-foreground dark:border-foreground-dark rounded-full flex justify-center items-center text-foreground dark:text-foreground-dark [&#38;>*:hover]:brightness-75 md:opacity-80 [&#38;>*]:cursor-pointer" data-astro-cid-lgn464si> <button data-theme="theme-auto" aria-label="Auto Theme" title="Set theme to follow system preference" class="theme-button theme-auto" data-astro-cid-lgn464si> <svg width="1em" height="1em" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:brightness-auto">   <symbol id="ai:mdi:brightness-auto" viewBox="0 0 24 24"><path fill="currentColor" d="m14.3 16l-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69L8.69 4H4v4.69L.69 12L4 15.31V20h4.69L12 23.31L15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></symbol><use href="#ai:mdi:brightness-auto"></use>  </svg> </button> <button data-theme="theme-light" aria-label="Light Theme" title="Set theme to light" class="theme-button theme-light" data-astro-cid-lgn464si> <svg width="1em" height="1em" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:white-balance-sunny">   <symbol id="ai:mdi:white-balance-sunny" viewBox="0 0 24 24"><path fill="currentColor" d="m3.55 19.09l1.41 1.41l1.8-1.79l-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71l1.8 1.79l1.41-1.41l-1.79-1.8M20.45 5l-1.41-1.4l-1.8 1.79l1.42 1.42M13 1h-2v3h2M6.76 5.39L4.96 3.6L3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"/></symbol><use href="#ai:mdi:white-balance-sunny"></use>  </svg> </button> <button data-theme="theme-dark" aria-label="Dark Theme" title="Set theme to dark" class="theme-button theme-dark" data-astro-cid-lgn464si> <svg width="1em" height="1em" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:moon-and-stars">   <symbol id="ai:mdi:moon-and-stars" viewBox="0 0 24 24"><path fill="currentColor" d="m17.75 4.09l-2.53 1.94l.91 3.06l-2.63-1.81l-2.63 1.81l.91-3.06l-2.53-1.94L12.44 4l1.06-3l1.06 3zm3.5 6.91l-1.64 1.25l.59 1.98l-1.7-1.17l-1.7 1.17l.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85c-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14c.4-.4.82-.76 1.27-1.08c.75-.53 1.93.36 1.85 1.19c-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82c-2.81 3.14-2.7 7.96.31 10.98c3.02 3.01 7.84 3.12 10.98.31"/></symbol><use href="#ai:mdi:moon-and-stars"></use>  </svg> </button> </div>  </div> <button class="md:hidden cursor-pointer" id="nav-open-btn" aria-label="Open navigation menu" title="Open navigation menu"> <svg width="32" height="32" aria-hidden="true" data-icon="mdi:menu">   <symbol id="ai:mdi:menu" viewBox="0 0 24 24"><path fill="currentColor" d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></symbol><use href="#ai:mdi:menu"></use>  </svg> </button> <!-- Mobile nav --> <div class="translate-x-full md:hidden fixed top-0 right-0 bg-background dark:bg-background-dark h-screen w-5/6 px-8 py-6 transition-transform z-40 border-l-[1px] border-background" id="mobile-menu"> <button id="nav-close-btn" class="ml-auto block cursor-pointer" aria-label="Close navigation menu" title="Close navigation menu"> <svg width="32" height="32" aria-hidden="true" data-icon="mdi:close">   <symbol id="ai:mdi:close" viewBox="0 0 24 24"><path fill="currentColor" d="M19 6.41L17.59 5L12 10.59L6.41 5L5 6.41L10.59 12L5 17.59L6.41 19L12 13.41L17.59 19L19 17.59L13.41 12z"/></symbol><use href="#ai:mdi:close"></use>  </svg> </button> <div class="flex flex-col h-full items-start gap-8 pt-16"> <a href="/" class="text-4xl font-light" target="_self" data-astro-cid-rieiwi5x> Blog </a> <a href="https://github.com/sponsors/ghostdogpr" class="text-4xl font-light" target="_blank" data-astro-cid-rieiwi5x> Sponsor </a>  <div class="mt-4 border-[1px] border-foreground dark:border-foreground-dark rounded-full flex justify-center items-center text-foreground dark:text-foreground-dark [&#38;>*:hover]:brightness-75 md:opacity-80 [&#38;>*]:cursor-pointer" data-astro-cid-lgn464si> <button data-theme="theme-auto" aria-label="Auto Theme" title="Set theme to follow system preference" class="theme-button theme-auto" data-astro-cid-lgn464si> <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:brightness-auto">   <use href="#ai:mdi:brightness-auto"></use>  </svg> </button> <button data-theme="theme-light" aria-label="Light Theme" title="Set theme to light" class="theme-button theme-light" data-astro-cid-lgn464si> <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:white-balance-sunny">   <use href="#ai:mdi:white-balance-sunny"></use>  </svg> </button> <button data-theme="theme-dark" aria-label="Dark Theme" title="Set theme to dark" class="theme-button theme-dark" data-astro-cid-lgn464si> <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" data-astro-cid-lgn464si="true" class="duration-0 text-2xl md:text-xl" data-icon="mdi:moon-and-stars">   <use href="#ai:mdi:moon-and-stars"></use>  </svg> </button> </div>  </div> </div> </div> </nav> <script type="module">function e(){document.querySelector("#mobile-menu")?.classList.toggle("mobile-nav-open")}document.querySelector("#nav-open-btn")?.addEventListener("click",e);document.querySelector("#nav-close-btn")?.addEventListener("click",e);</script> </header> <script>
	function reComputeTheme() {
		if (
			localStorage.theme === 'dark' ||
			(!('theme' in localStorage) &&
				window.matchMedia('(prefers-color-scheme: dark)').matches)
		) {
			document.documentElement.classList.add('dark')
		} else {
			document.documentElement.classList.remove('dark')
		}

		const theme = localStorage.theme || 'auto'
		document
			.querySelectorAll(`[data-theme="theme-${theme}"]`)
			.forEach((el) => el.classList.add('active'))
	}

	function addThemeEventListeners() {
		themeButtons = document.querySelectorAll('.theme-button')
		themeButtons.forEach((button) => {
			button.addEventListener('click', () => {
				themeButtons.forEach((btn) => btn.classList.remove('active'))
				button.classList.add('active')
				if (button.dataset.theme === 'theme-auto') {
					localStorage.removeItem('theme')
					reComputeTheme()
				} else {
					localStorage.theme = button.dataset.theme.replace('theme-', '')
					document.documentElement.classList.toggle(
						'dark',
						button.dataset.theme === 'theme-dark'
					)
				}
			})
		})
	}

	// Set active class on OS theme change
	window
		.matchMedia('(prefers-color-scheme: dark)')
		.addEventListener('change', (_e) => {
			reComputeTheme()
		})

	// run recomputeTheme when screen crosses 768px
	window.matchMedia('(min-width: 768px)').addEventListener('change', (_e) => {
		addThemeEventListeners()
		reComputeTheme()
	})

	reComputeTheme()

	// Run on page load
	window.addEventListener('DOMContentLoaded', () => {
		addThemeEventListeners()
		reComputeTheme()
	})
</script>  <main> <article> <div class="app-container flex flex-col lg:flex-row-reverse justify-between gap-8 py-24 relative"> <div class="md:w-1/4 relative"> <div class="sticky top-0 md:top-28 hidden lg:block"> <div></div> </div> </div> <div class="grow w-full md:max-w-[75ch]"> <div> <h1 class="text-4xl sm:text-5xl leading-snug pt-12 font-bold"> Supporting high-performance response streaming in Shardcake </h1> <div class="text-lg flex items-center gap-4 flex-wrap py-8"> <!-- Publish date --> <span> <svg width="1em" height="1em" class="inline-block text-primary dark:text-primary-dark" data-icon="mdi:calendar-month-outline">   <symbol id="ai:mdi:calendar-month-outline" viewBox="0 0 24 24"><path fill="currentColor" d="M7 11h2v2H7zm14-6v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.1.9-2 2-2h1V1h2v2h8V1h2v2h1a2 2 0 0 1 2 2M5 7h14V5H5zm14 12V9H5v10zm-4-6v-2h2v2zm-4 0v-2h2v2zm-4 2h2v2H7zm8 2v-2h2v2zm-4 0v-2h2v2z"/></symbol><use href="#ai:mdi:calendar-month-outline"></use>  </svg> <time datetime="2024-04-01T00:00:00.000Z"> 1 Apr 2024 </time> </span> <!-- Updated date -->  <!-- Read time --> <span> <svg width="1em" height="1em" class="inline-block text-primary dark:text-primary-dark" data-icon="mdi:clock-time-four-outline">   <symbol id="ai:mdi:clock-time-four-outline" viewBox="0 0 24 24"><path fill="currentColor" d="M12 20c4.4 0 8-3.6 8-8s-3.6-8-8-8s-8 3.6-8 8s3.6 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10S2 17.5 2 12S6.5 2 12 2m5 11.9l-.7 1.3l-5.3-2.9V7h1.5v4.4z"/></symbol><use href="#ai:mdi:clock-time-four-outline"></use>  </svg> 12 min read </span> </div>  <img src="/_astro/cover.BvPF0nQt_15Ssss.webp" alt="Supporting high-performance response streaming in Shardcake" loading="lazy" decoding="async" fetchpriority="auto" width="853" height="480" class="rounded-lg mb-8">  </div> <div class="prose prose-neutral prose-lg md:prose-xl dark:prose-invert prose-img:rounded-xl prose-figure:text-center prose-img:mx-auto">  <p><a href="https://devsisters.github.io/shardcake/">Shardcake</a> is a Scala open source library I created in 2022 to easily distribute entities across multiple servers (<em>sharding</em>) and to interact with them using their ID without knowing their actual location (<em>location transparency</em>).</p>
<p>To support a real-life use case, I recently added the ability to stream messages from remote entities to multiple recipients. While doing so, I encountered a few issues and challenges that I am sharing here in the hope that they are helpful to others. Knowledge of zio or cats-effect is recommended (Shardcake itself is based on zio/zio-streams, but most concepts are the same in cats-effect/fs2).</p>
<h3 id="basics">Basics</h3>
<p>Let’s look at a very simplified example first. To communicate with remote entities, we send them messages, which are typically defined in an <code>enum</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">enum</span><span style="color:#B392F0"> UserMessage</span><span style="color:#E1E4E8"> {</span></span>
<span class="line"><span style="color:#F97583">  case</span><span style="color:#B392F0"> Greet</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">message</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">replier</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">Replier</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">])</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>Our <code>User</code> entity will be able to handle messages of type <code>UserMessage</code>. There is only one subtype: <code>Greet</code>. It contains a <code>Replier[String]</code>, which means that the entity can reply to the message sender with a <code>String</code> by simply calling <code>replier.reply</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">class</span><span style="color:#B392F0"> User</span><span style="color:#E1E4E8"> {</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> handle</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">protocol</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">UserMessage</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">=</span></span>
<span class="line"><span style="color:#E1E4E8">    protocol </span><span style="color:#F97583">match</span><span style="color:#E1E4E8"> {</span></span>
<span class="line"><span style="color:#F97583">      case</span><span style="color:#B392F0"> UserMessage</span><span style="color:#E1E4E8">.</span><span style="color:#B392F0">Greet</span><span style="color:#E1E4E8">(message, replier) </span><span style="color:#F97583">=></span><span style="color:#E1E4E8"> </span></span>
<span class="line"><span style="color:#E1E4E8">        replier.reply(</span><span style="color:#F97583">s</span><span style="color:#9ECBFF">"Received </span><span style="color:#E1E4E8">$message</span><span style="color:#9ECBFF">"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>On the sender side, we need a <code>Messenger[UserMessage]</code>, and we can use its <code>send</code> function to send a message to any <code>User</code> entity and get back a <code>String</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">class</span><span style="color:#B392F0"> Service</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">user</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">Messenger</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">UserMessage</span><span style="color:#E1E4E8">]) {</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> greetUser</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">userId</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">message</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">)</span><span style="color:#F97583">:</span><span style="color:#B392F0"> Task</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">=</span></span>
<span class="line"><span style="color:#E1E4E8">    user.send(userId)(</span><span style="color:#B392F0">UserMessage</span><span style="color:#E1E4E8">.</span><span style="color:#B392F0">Greet</span><span style="color:#E1E4E8">(message, _))</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>The default implementation of the transport layer uses gRPC to communicate between the sender and the remote entity, but it is possible to plug in a different protocol instead.</p>
<h3 id="the-problem">The problem</h3>
<p>I’ve been using Shardcake at work for a couple of years already, and our workflows usually look like this:</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="592" height="181" src="/_astro/image-1.CnjxT3uR_1E24Av.webp" ></figure>
<p>Client requests hit a first pod’s gRPC server, then each request is dispatched to a service that eventually calls the <code>send</code> method we just saw. That triggers a call to another pod (unless we’re lucky and the entity is hosted by the same pod), also using gRPC. The second pod’s gRPC server forwards the message to the local entity, and the entity’s reply is sent back as a response to the gRPC call. The service can then process this response and return a response to the client.</p>
<p>However, we had to develop a new feature where multiple users would be part of a “channel”, and any action from one user should be forwarded to all users in the same channel in real time.</p>
<p>That meant that the workflow wouldn’t be that simple anymore. Upon receiving a message, the entity would have to dispatch the reply back to multiple clients instead of one.</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="591" height="482" src="/_astro/image-2.fEkx4qZ4_Z1m41zG.webp" ></figure>
<h3 id="initial-support">Initial support</h3>
<p>The implementation of <code>send</code> took two parameters: an entity ID (to locate our entity in one of the pods) as well as a function providing a <code>Replier[Res]</code> to construct a <code>Msg</code> (<code>Msg</code> being the message protocol of the entity). This function returns a <code>Task[Res]</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> send</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">](</span><span style="color:#FFAB70">entityId</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">)(</span></span>
<span class="line"><span style="color:#FFAB70">  msg</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">Replier</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">=></span><span style="color:#B392F0"> Msg</span></span>
<span class="line"><span style="color:#E1E4E8">)</span><span style="color:#F97583">:</span><span style="color:#B392F0"> Task</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">case</span><span style="color:#F97583"> class</span><span style="color:#B392F0"> Replier</span><span style="color:#E1E4E8">[</span><span style="color:#F97583">-</span><span style="color:#B392F0">R</span><span style="color:#E1E4E8">] {</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> reply</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">reply</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">R</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">=</span><span style="color:#F97583"> ???</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>I created a similar API for being able to reply not with a single response but with a stream of responses. <code>sendStream</code> returns a <code>Stream</code> of <code>Res</code>, and the entity should now call <code>replyStream</code> with a <code>Stream</code> of <code>Res</code> instead of a single <code>Res</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> sendStream</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">](</span><span style="color:#FFAB70">entityId</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">String</span><span style="color:#E1E4E8">)(</span></span>
<span class="line"><span style="color:#FFAB70">  msg</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">StreamReplier</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">=></span><span style="color:#B392F0"> Msg</span></span>
<span class="line"><span style="color:#E1E4E8">)</span><span style="color:#F97583">:</span><span style="color:#B392F0"> Task</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Stream</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Throwable</span><span style="color:#E1E4E8">, </span><span style="color:#B392F0">Res</span><span style="color:#E1E4E8">]]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">case</span><span style="color:#F97583"> class</span><span style="color:#B392F0"> StreamReplier</span><span style="color:#E1E4E8">[</span><span style="color:#F97583">-</span><span style="color:#B392F0">R</span><span style="color:#E1E4E8">] {</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> replyStream</span><span style="color:#E1E4E8">(</span><span style="color:#FFAB70">replies</span><span style="color:#E1E4E8">: </span><span style="color:#B392F0">Stream</span><span style="color:#E1E4E8">[</span><span style="color:#B392F0">Nothing</span><span style="color:#E1E4E8">, </span><span style="color:#B392F0">R</span><span style="color:#E1E4E8">]) </span><span style="color:#F97583">=</span><span style="color:#F97583"> ???</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>There were 2 major differences in the implementation compared to the initial <code>send</code>:</p>
<ul>
<li>
<p>I was mostly using <code>Promise</code> to handle replies from entities internally, but that didn’t work with multiple replies. I had to use <code>Queue</code> to support multiple replies, but I didn’t want to slow down the one-reply use case, so I ended up creating an abstraction called <code>ReplyChannel</code> that can wrap either a <code>Promise</code> or a <code>Queue</code> depending on the situation.</p>
</li>
<li>
<p>Instead of unary gRPC calls for internal communication between pods, I had to use gRPC streams.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#6A737D">// unary case</span></span>
<span class="line"><span style="color:#E1E4E8">rpc </span><span style="color:#B392F0">Send</span><span style="color:#E1E4E8"> (</span><span style="color:#B392F0">SendRequest</span><span style="color:#E1E4E8">) returns (</span><span style="color:#B392F0">SendResponse</span><span style="color:#E1E4E8">) {}</span></span>
<span class="line"><span style="color:#6A737D">// streaming case</span></span>
<span class="line"><span style="color:#E1E4E8">rpc </span><span style="color:#B392F0">SendStream</span><span style="color:#E1E4E8"> (</span><span style="color:#B392F0">SendRequest</span><span style="color:#E1E4E8">) returns (stream </span><span style="color:#B392F0">SendResponse</span><span style="color:#E1E4E8">) {}</span></span></code></pre>
</li>
</ul>
<h3 id="chunking-express">Chunking Express</h3>
<p>Once the implementation of <code>sendStream</code> was finished, I could finally put together a proof-of-concept for our multi-user channel use case and start measuring the performance. And it was… slow, very slow.</p>
<p>I had a look at the profiler, and what I observed was that most of the CPU time was not spent in my code or even in Shardcake’s code but in <code>ZIO</code> and <code>ZStream</code> internals. Seeing too much time in ZIO’s runtime usually indicates that you are running too many IO loops.</p>
<p>In our test case, each client was sending multiple messages per second, and each message was broadcasted to all other clients, so we ended up broadcasting a huge number of messages.</p>
<p>When working with streams and dealing with a lot of messages, it’s important to consider <strong>chunking</strong>. Libraries like zio-streams and fs2 internally group elements into <strong>chunks</strong> to speed up internal processing. Both these libraries are pull-based, which means streams pull elements from upstream when they are ready to be consumed. This pulling mechanism has a cost, and doing it one element at a time is often quite inefficient when dealing with large streams of data. For example, <code>ZStream.fromInputStream</code> pulls chunks of size 4096 from their source by default, while <code>Files.readAll</code> in fs2 takes chunks of size 64KB.</p>
<p>Those chunks are internal though, you don’t see them in the signature of your streams unless you explicitly surface them by transforming your <code>Stream[A]</code> to <code>Stream[Chunk[A]]</code>. Most <code>Stream</code> constructors are smart enough that they apply some chunking by default. In our Shardcake case, my streams came from <code>Queue</code>, and the default <code>ZStream.fromQueue</code> also pulls chunks of size up to 4096 from the queue.</p>
<p>Why should we care about it?</p>
<p>The problem with the fact that these chunks are internal is that there are some operators that don’t operate on chunks but on individual elements, or worse, operators that destroy the chunking.</p>
<p>If you call <code>map</code> on your stream, internally it will call <code>map</code> on each chunk, which is very fast because it is a pure operation. However, if you call <code>mapZIO</code> or <code>tap</code>, you are going to run a <code>ZIO</code> effect for each individual element, which is potentially going to slow down your stream processing a lot. Prefer <code>mapChunksZIO</code>, for example, if you are able to run a single <code>ZIO</code> for the whole <code>Chunk</code> instead. Similarly, <code>runForeachChunk</code> will be faster than <code>runForeach</code> if you are able to process a chunk at once.</p>
<p>In Shardcake, there were a few cases where I was using individual processing:</p>
<ul>
<li>
<p><code>.mapZIO(serialization.encode)</code> was used for serializing messages, which is a very fast operation. I changed it to <code>.mapChunksZIO(serialization.encodeChunk)</code> to serialize a whole chunk of messages at once in a single <code>ZIO</code> and reduce the unnecessary overhead of the IO loop. The same thing applies to deserialization.</p>
</li>
<li>
<p>I also had a case where I was doing <code>stream.runForeach(a => queue.offer(Take.single(a)))</code>, which involves consuming a stream and enqueuing every element into a queue of <code>Take</code>. There is a much better way of doing this since <code>Take.chunk</code> exists: <code>stream.runForeachChunk(c => queue.offer(Take.chunk(c)))</code> will process whole chunks at once. There’s even a <code>stream.runIntoQueue</code> that essentially does that.</p>
</li>
<li>
<p>A tricky case is <code>ZStream#buffer</code>, which destroys the chunking. I was not using it directly, but it was being used in zio-grpc to apply back-pressure on streams and avoid running out of memory in Netty. <a href="https://github.com/scalapb/zio-grpc/pull/578">I added the ability</a> to avoid this call to <code>buffer</code>, which was better for my use case of sending a lot of small messages.</p>
</li>
</ul>
<p>I also added extra buffering inside my channels: instead of trying to forward messages to other clients immediately, I put them in a <code>Queue</code> and took all elements from the <code>Queue</code> every n milliseconds to send them to all clients. That way, I increased the chance of having actual chunks with multiple messages rather than many chunks of size 1.</p>
<h3 id="mysterious-back-pressure">Mysterious back pressure</h3>
<p>Once all these changes were applied, we were able to support a much higher throughput and started testing with hundreds of channels and thousands of users.</p>
<p>We quickly found that we were reaching a limit: at some rate of messages, we couldn’t get any faster even though the CPU was not at 100%. We tried adding more pods: no improvements. We tried giving more CPU to existing pods: no improvements. Our worst nightmare was happening: the system was not scalable.</p>
<p>After a lot of digging, debugging, and logging in the application, we were able to find the culprit: it was not the internal communication but the communication with clients that was slowing us down. Netty was applying back-pressure because it couldn’t send messages fast enough. The answer finally came from our DevOps: our <a href="https://istio.io/latest/docs/tasks/traffic-management/ingress/ingress-control/">Istio Ingress Gateway</a> was at 100% CPU during each of the tests and couldn’t handle all the messages. In other words, the traffic between the client and the server was being throttled.</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="890" height="261" src="/_astro/image-3.BJaXvUPB_2okB4y.webp" ></figure>
<p>We lifted that immediately and, to our relief, were able to process a lot more messages. That was a good lesson for us: when nothing makes sense anymore, look for external factors!</p>
<h3 id="thread-contention">Thread contention</h3>
<p>At that point, we noticed a warning in Datadog’s live profiler:</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="1706" height="398" src="/_astro/image-4.D-_Ja6DV_ZMKSmX.webp" ></figure>
<p>We took a closer look at threads and found that there were a LOT of threads created by the grpc-java executor (grpc-java is used by zio-grpc under the hood).</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="598" height="408" src="/_astro/image-5.CsF_VUcN_jPaQA.webp" ></figure>
<p>These threads were not even that busy, but it kept creating new ones. A small research led us to the <a href="https://stackoverflow.com/a/42422045">following SO message</a>:</p>
<blockquote>
<p>By default, gRPC uses a cached thread pool so that it is very easy to get started. However, it is strongly recommended you provide your own executor. The reason is that the default thread pool behaves badly under load, creating new threads when the rest are busy.</p>
</blockquote>
<p>In fact, it turns out the <a href="https://grpc.io/docs/guides/performance/#java">official docs</a> recommend that you “<em>provide a custom executor that limits the number of threads, based on your workload (cached (default), fixed, fork join, etc.)</em>”. There is a long <a href="https://github.com/grpc/grpc-java/issues/7381">GitHub issue</a> about whether the defaults should be changed or not, but they haven’t because using a fixed-size thread pool can lead to deadlocks if you are blocking in those threads. We’re using ZIO, so we should be safe, right?</p>
<p>We proceeded to change the executor (which required <a href="https://github.com/devsisters/shardcake/pull/113">exposing the setting in Shardcake</a>) to ForkJoinPool, and performance got even better, with now a very reasonable amount of threads. However, when our load test was about to end, all servers suddenly became unresponsive and were eventually killed by Kubernetes. Even the health check endpoint was not responding.</p>
<p>Fortunately, the Datadog profiler was able to capture one last profile before the servers were killed. It showed that all threads from our grpc executor threadpool were waiting on the same lock.</p>
<figure class="rehype-figure-title"><img  loading="lazy" decoding="async" fetchpriority="auto" width="3520" height="1772" src="/_astro/image-6.DS0rMevT_1pHNho.webp" ></figure>
<p>When a stream is disconnected on the client side, grpc-java calls an <code>onCancel</code> callback to let us know about it. In zio-grpc, this <code>onCancel</code> triggers the interruption of the fiber running the stream by calling <code>fiber.interrupt</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#F97583">override</span><span style="color:#F97583"> def</span><span style="color:#B392F0"> onCancel</span><span style="color:#E1E4E8">()</span><span style="color:#F97583">:</span><span style="color:#B392F0"> Unit</span><span style="color:#F97583"> =</span></span>
<span class="line"><span style="color:#B392F0">  Unsafe</span><span style="color:#E1E4E8">.unsafe { </span><span style="color:#F97583">implicit</span><span style="color:#E1E4E8"> u </span><span style="color:#F97583">=></span></span>
<span class="line"><span style="color:#E1E4E8">    runtime.unsafe.run(fiber.interrupt.unit).getOrThrowFiberFailure()</span></span>
<span class="line"><span style="color:#E1E4E8">  }</span></span></code></pre>
<p>There is a catch, though: in ZIO, <code>fiber.interrupt</code> does not return immediately; it returns once the fiber is interrupted. This means that we are blocking the current thread until the interruption is done. The interruption is processed by the ZIO scheduler threadpool, so that should not be a problem.</p>
<p>However, looking at the creation of the fiber (the code has been simplified a bit):</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="scala"><code><span class="line"><span style="color:#E1E4E8">stream.onExit(ex </span><span style="color:#F97583">=></span><span style="color:#E1E4E8"> call.close(...)).forkDaemon</span></span></code></pre>
<p><code>onExit</code> adds a finalizer so that, when the stream is interrupted, we call <code>close</code> from the grpc-java API. This means that we need some code to be executed by grpc-java to complete our interruption.</p>
<p>With a single stream, this is not a problem as it can be done by another thread. But if multiple streams are interrupted at the same time, we might end up in the situation we observed where all threads from the fixed-size threadpool are waiting on interruption and there are no more threads to process the <code>close</code>, forming a deadlock.</p>
<p>To prevent that, I had to replace <code>.interrupt</code> with <code>.interruptFork</code> <a href="https://github.com/scalapb/zio-grpc/pull/612">in zio-grpc</a>. Unlike <code>interrupt</code>, <code>interruptFork</code> runs the interruption in a separate fiber and returns instantly, removing the risk of blocking threads. Note that at the time of writing, there was no new release of zio-grpc so you have to use the latest snapshot to get this fix.</p>
<p>After this change, our load test performed pretty well and we successfully went to production last week, with our reply streams pushing more than 100k messages per second to thousands of players.</p>
<h3 id="future-improvements">Future improvements</h3>
<p>When looking at the CPU usage on our application, because the business logic is pretty basic, most of the CPU time is still spent in the ZIO runtime, for processing the multiple streams, hubs, and queues that we’re using. Any improvements in that area would be interesting for our use case, and it looks like <a href="https://github.com/zio/zio/pull/8582">some are coming</a> in ZIO 2.1, while <a href="https://github.com/zio/zio/issues/8611">others may come later</a>. There is also a branch of ZIO with <a href="https://github.com/zio/zio/pull/8068">a dedicated runtime for streams</a>, but I don’t know if and when it will become available.</p>
<p>You might also have noticed that I only implemented “streaming replies” and not “streaming requests”. This is totally doable, and we could use bidirectional gRPC streams under the hood. I found this less useful since you can simply call <code>send</code> multiple times if you have a stream of requests. In both cases, it will use an HTTP/2 connection under the hood, so the performance gain might not be that big, but it’s definitely something that could be added if needed.</p>
<p>I hope that sharing my experience was useful, and I’m looking forward to hearing from other Shardcake users if you try to use this new feature!</p>  </div> </div> </div> </article> </main>  <footer> <div class="app-container grid md:grid-cols-3 gap-12 py-16 border-t-2 border-foreground/50 dark:border-foreground-dark/50"> <div> <a href="/" class="block w-fit" aria-label="Home"> <svg width="36" height="36" viewBox="0 0 36 36" fill="none">
  <rect width="36" height="36" rx="8" fill="currentColor" opacity="0.1" />
  <text x="18" y="25" font-family="system-ui, -apple-system, sans-serif" font-size="18" font-weight="700" fill="currentColor" text-anchor="middle">PR</text>
</svg> </a> </div> <div> <h3 class="font-semibold text-2xl">Links</h3> <div class="flex flex-wrap gap-4 mt-4"> <a class="text-lg" href target="_blank" rel="noopener noreferrer"> Blog </a><a class="text-lg" href="https://github.com/sponsors/ghostdogpr" target="_blank" rel="noopener noreferrer"> Sponsor </a> <a href="/rss.xml" target="_blank" rel="noopener noreferrer" class="text-lg" aria-label="RSS Feed"> <svg width="1em" height="1em" class="w-6 h-6" data-icon="mdi:rss">   <symbol id="ai:mdi:rss" viewBox="0 0 24 24"><path fill="currentColor" d="M6.18 15.64a2.18 2.18 0 0 1 2.18 2.18C8.36 19 7.38 20 6.18 20C5 20 4 19 4 17.82a2.18 2.18 0 0 1 2.18-2.18M4 4.44A15.56 15.56 0 0 1 19.56 20h-2.83A12.73 12.73 0 0 0 4 7.27zm0 5.66a9.9 9.9 0 0 1 9.9 9.9h-2.83A7.07 7.07 0 0 0 4 12.93z"/></symbol><use href="#ai:mdi:rss"></use>  </svg> </a> </div> </div> <div> <h3 class="font-semibold text-2xl">Socials</h3> <div class="flex flex-wrap gap-4 mt-4"> <a class="text-lg" href="https://github.com/ghostdogpr" target="_blank" rel="noopener noreferrer"> GitHub </a><a class="text-lg" href="https://www.linkedin.com/in/pierrericadat/" target="_blank" rel="noopener noreferrer"> LinkedIn </a><a class="text-lg" href="https://twitter.com/ghostdogpr" target="_blank" rel="noopener noreferrer"> X / Twitter </a> </div> </div> </div> <div class="app-container flex justify-between items-center pb-6 text-center"> <p class="text-left md:text-center w-full">
Theme: <a class="underline" href="https://github.com/yashjawale/saral-theme-astro" target="_blank">Saral</a> </p> </div> </footer> </body></html>